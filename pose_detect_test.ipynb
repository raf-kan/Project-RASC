{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np \n",
    "from time import time\n",
    "import mediapipe as mp \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseDetection():\n",
    "    def __init__(self, input_path):\n",
    "        self.input = input_path\n",
    "        return None\n",
    "    \n",
    "    def detect_image(input_image_path):\n",
    "\n",
    "        mp_pose = mp.solutions.pose\n",
    "        pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence = 0.3, model_complexity=2)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        \n",
    "        input_image = cv2.imread(input_image_path)\n",
    "        results = pose.process(cv2.cvtColor(input_image,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        landmark_points = {}\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            for i in range(32):\n",
    "\n",
    "                landmark_points[i] = {i: \n",
    "                                        {\n",
    "                                            \"name\": mp_pose.PoseLandmark(i).name,\n",
    "                                            \"x\": results.pose_landmarks.landmark[mp_pose.PoseLandmark(i).value].x,\n",
    "                                            \"y\": results.pose_landmarks.landmark[mp_pose.PoseLandmark(i).value].y,\n",
    "                                            \"z\": results.pose_landmarks.landmark[mp_pose.PoseLandmark(i).value].z\n",
    "                                        }\n",
    "                                        }\n",
    "\n",
    "        # return output_image, landmark_points\n",
    "        return landmark_points\n",
    "\n",
    "    def process_landmarks(self, imageIn):\n",
    "\n",
    "        mp_pose = mp.solutions.pose\n",
    "        pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence = 0.3, model_complexity=2)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "        results = pose.process(cv2.cvtColor(imageIn,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        landmark_points = {}\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            for i in range(32):\n",
    "\n",
    "                landmark_points[i] = {i: \n",
    "                                        {\n",
    "                                            \"name\": mp_pose.PoseLandmark(i).name,\n",
    "                                            \"x\": results.pose_landmarks.landmark[mp_pose.PoseLandmark(i).value].x,\n",
    "                                            \"y\": results.pose_landmarks.landmark[mp_pose.PoseLandmark(i).value].y,\n",
    "                                            \"z\": results.pose_landmarks.landmark[mp_pose.PoseLandmark(i).value].z\n",
    "                                        }\n",
    "                                        }\n",
    "\n",
    "        # return output_image, landmark_points\n",
    "        return landmark_points\n",
    "\n",
    "    def detect_image_test(self):\n",
    "\n",
    "        input_image = cv2.imread(self.input)\n",
    "\n",
    "        lp = self.process_landmarks(input_image)\n",
    "\n",
    "        return lp\n",
    "\n",
    "    def detect_video(self):\n",
    "        \n",
    "        vcap = cv2.VideoCapture(self.input)\n",
    "\n",
    "        if (vcap.isOpened() == False): raise IsADirectoryError(\"File does not exist or error on loading video\")\n",
    "\n",
    "        ret, frame = vcap.read()\n",
    "\n",
    "        cv2.imshow('video',frame)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def lo(self):\n",
    "\n",
    "        out = cv2.imread(self.input)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: {'name': 'NOSE', 'x': 0.4094741940498352, 'y': 0.17661041021347046, 'z': -0.6862496137619019}}, 1: {1: {'name': 'LEFT_EYE_INNER', 'x': 0.4082598388195038, 'y': 0.1580463945865631, 'z': -0.7061542868614197}}, 2: {2: {'name': 'LEFT_EYE', 'x': 0.4176032245159149, 'y': 0.1530049592256546, 'z': -0.7070907950401306}}, 3: {3: {'name': 'LEFT_EYE_OUTER', 'x': 0.42633527517318726, 'y': 0.14826741814613342, 'z': -0.7069729566574097}}, 4: {4: {'name': 'RIGHT_EYE_INNER', 'x': 0.37762948870658875, 'y': 0.1651732623577118, 'z': -0.6679149270057678}}, 5: {5: {'name': 'RIGHT_EYE', 'x': 0.3659151792526245, 'y': 0.1653871089220047, 'z': -0.6695122718811035}}, 6: {6: {'name': 'RIGHT_EYE_OUTER', 'x': 0.3546685576438904, 'y': 0.16542376577854156, 'z': -0.67067551612854}}, 7: {7: {'name': 'LEFT_EAR', 'x': 0.45634108781814575, 'y': 0.1209365576505661, 'z': -0.5509464144706726}}, 8: {8: {'name': 'RIGHT_EAR', 'x': 0.3578430116176605, 'y': 0.14853018522262573, 'z': -0.3706682324409485}}, 9: {9: {'name': 'MOUTH_LEFT', 'x': 0.4436335563659668, 'y': 0.1742924302816391, 'z': -0.592000424861908}}, 10: {10: {'name': 'MOUTH_RIGHT', 'x': 0.41020873188972473, 'y': 0.18311750888824463, 'z': -0.5462323427200317}}, 11: {11: {'name': 'LEFT_SHOULDER', 'x': 0.7144362926483154, 'y': 0.11467136442661285, 'z': -0.3574051260948181}}, 12: {12: {'name': 'RIGHT_SHOULDER', 'x': 0.32039663195610046, 'y': 0.21220026910305023, 'z': -0.12884163856506348}}, 13: {13: {'name': 'LEFT_ELBOW', 'x': 0.7953904867172241, 'y': 0.2791305184364319, 'z': -0.32822391390800476}}, 14: {14: {'name': 'RIGHT_ELBOW', 'x': 0.5042058229446411, 'y': 0.33782047033309937, 'z': -0.0610489696264267}}, 15: {15: {'name': 'LEFT_WRIST', 'x': 0.8222739696502686, 'y': 0.4209998548030853, 'z': -0.4541684091091156}}, 16: {16: {'name': 'RIGHT_WRIST', 'x': 0.7345155477523804, 'y': 0.43602627515792847, 'z': -0.3230796456336975}}, 17: {17: {'name': 'LEFT_PINKY', 'x': 0.8430514335632324, 'y': 0.47449734807014465, 'z': -0.5450637936592102}}, 18: {18: {'name': 'RIGHT_PINKY', 'x': 0.7699346542358398, 'y': 0.4790908396244049, 'z': -0.43001484870910645}}, 19: {19: {'name': 'LEFT_INDEX', 'x': 0.8230286836624146, 'y': 0.47692686319351196, 'z': -0.6149703860282898}}, 20: {20: {'name': 'RIGHT_INDEX', 'x': 0.8003583550453186, 'y': 0.4722435772418976, 'z': -0.4877326786518097}}, 21: {21: {'name': 'LEFT_THUMB', 'x': 0.8056743741035461, 'y': 0.4566796123981476, 'z': -0.47765052318573}}, 22: {22: {'name': 'RIGHT_THUMB', 'x': 0.7918647527694702, 'y': 0.45547962188720703, 'z': -0.35191217064857483}}, 23: {23: {'name': 'LEFT_HIP', 'x': 0.846024751663208, 'y': 0.4187066853046417, 'z': -0.0800502747297287}}, 24: {24: {'name': 'RIGHT_HIP', 'x': 0.6082894206047058, 'y': 0.43741732835769653, 'z': 0.0791044756770134}}, 25: {25: {'name': 'LEFT_KNEE', 'x': 0.8810001611709595, 'y': 0.6575034856796265, 'z': -0.14765480160713196}}, 26: {26: {'name': 'RIGHT_KNEE', 'x': 0.4715217649936676, 'y': 0.6556953191757202, 'z': 0.03238467499613762}}, 27: {27: {'name': 'LEFT_ANKLE', 'x': 0.8716713190078735, 'y': 0.9078700542449951, 'z': 0.048389632254838943}}, 28: {28: {'name': 'RIGHT_ANKLE', 'x': 0.210755854845047, 'y': 0.8724451661109924, 'z': 0.28410542011260986}}, 29: {29: {'name': 'LEFT_HEEL', 'x': 0.8556816577911377, 'y': 0.9174453020095825, 'z': 0.04715634509921074}}, 30: {30: {'name': 'RIGHT_HEEL', 'x': 0.24019120633602142, 'y': 0.9107590317726135, 'z': 0.29804831743240356}}, 31: {31: {'name': 'LEFT_FOOT_INDEX', 'x': 0.7303771376609802, 'y': 0.9431708455085754, 'z': -0.4095819592475891}}}\n"
     ]
    }
   ],
   "source": [
    "a = \"videos/sample_img.jpeg\"\n",
    "b = PoseDetection(input_path_2)\n",
    "c = b.lo()\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing singular image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_2 = \"videos/sample_img.jpeg\"\n",
    "test_2 = PoseDetection(input_path_2)\n",
    "\n",
    "lp_2 = test_2.detect_image_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'name': 'LEFT_EYE_INNER', 'x': 0.4082598388195038, 'y': 0.1580463945865631, 'z': -0.7061542868614197}}\n"
     ]
    }
   ],
   "source": [
    "print(lp_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT_EYE_INNER\n",
      "0.4082598388195038\n",
      "0.1580463945865631\n",
      "-0.7061542868614197\n"
     ]
    }
   ],
   "source": [
    "print(lp_2[1][1]['name'])\n",
    "print(lp_2[1][1]['x'])\n",
    "print(lp_2[1][1]['y'])\n",
    "print(lp_2[1][1]['z'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52  33  16]\n",
      " [ 49  31  13]\n",
      " [ 75  56  39]\n",
      " ...\n",
      " [192 143 113]\n",
      " [194 145 116]\n",
      " [195 146 117]]\n"
     ]
    }
   ],
   "source": [
    "video_test_path = \"videos/my_swing.mp4\"\n",
    "video_test = PoseDetection(video_test_path)\n",
    "\n",
    "video_out = video_test.detect_video()\n",
    "\n",
    "print(video_out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
